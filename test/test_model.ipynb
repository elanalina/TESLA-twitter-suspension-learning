{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is about how to get the prediction from the account and text and testing the running time of the whole process.\n",
    "#### By: Yue Yang(UIN: 625008110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our web app is built on python 3. Because of the difference between python 2.x and python 3.x, if we want to use the model created by the teammate, we must use the same versin python. So, we need check the version at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/letheyue/anaconda2/envs/yy_py3/bin/python\n",
      "3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:14:23) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "sys.version_info(major=3, minor=6, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import time\n",
    "\n",
    "api = twitter.Api(consumer_key=CONSUMER_KEY,\n",
    "                     consumer_secret=CONSUMER_SECRET,\n",
    "                     access_token_key=ACCESS_TOKEN_KEY,\n",
    "                     access_token_secret=ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: test the account model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 1.1: get the account feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_user(user_id=None, screen_name=None):\n",
    "    json = api.GetUser(user_id=user_id, screen_name=screen_name, include_entities=True, return_json=False)\n",
    "    json_data = json._json\n",
    "    \n",
    "    # feature Count of favorite tweets\n",
    "    Count_of_favorite_tweets = int(json_data['favourites_count'])\n",
    "    # feature Friends to follower ratio\n",
    "    if json_data['followers_count'] == 0:\n",
    "        Friends_to_follower_ratio = float(100000)\n",
    "    else:\n",
    "        Friends_to_follower_ratio = (float(json_data['friends_count']) / json_data['followers_count'])\n",
    "    # feature Total status count\n",
    "    Total_status_count = int(json_data['statuses_count'])\n",
    "    \n",
    "    # feature Default profile image & Default profile\n",
    "    # def_p_na','def_p_false','def_p_true'\n",
    "    if json_data['default_profile_image'] == 'FALSE':\n",
    "        Def_p_img_false = 1.0\n",
    "        Def_p_img_true = 0.0\n",
    "        Def_p_img_na = 0.0\n",
    "    elif json_data['default_profile_image'] == 'True':\n",
    "        Def_p_img_false = 0.0\n",
    "        Def_p_img_true = 1.0\n",
    "        Def_p_img_na = 0.0\n",
    "    else:\n",
    "        Def_p_img_false = 0.0\n",
    "        Def_p_img_true = 0.0\n",
    "        Def_p_img_na = 1.0\n",
    "\n",
    "    if json_data['default_profile'] == 'FALSE':\n",
    "        Def_p_false = 1.0\n",
    "        Def_p_true = 0.0\n",
    "        Def_p_na = 0.0\n",
    "    elif json_data['default_profile'] == 'True':\n",
    "        Def_p_false = 0.0\n",
    "        Def_p_true = 1.0\n",
    "        Def_p_na = 0.0\n",
    "    else:\n",
    "        Def_p_false = 0.0\n",
    "        Def_p_true = 0.0\n",
    "        Def_p_na = 1.0\n",
    "    \n",
    "    # feature Account ages\n",
    "    created_at = json_data['created_at']\n",
    "    Account_age = survival_time(created_at)\n",
    "\n",
    "    # feature User name and screen_name\n",
    "    User_name = json_data['name']\n",
    "    Screen_name = json_data['screen_name']\n",
    "    User_name_digit, User_name_char = counter(User_name)\n",
    "    Screen_name_digit, Screen_name_char = counter(Screen_name)\n",
    "\n",
    "    # feature Length of description and Description text\n",
    "    description_pre = json_data['description']\n",
    "    Description_length = len(description_pre)\n",
    "    \n",
    "    # feature Average tweet per day\n",
    "    # Average_tweets_per_day = Total_status_count / float(Account_age)\n",
    "\n",
    "    feature = pd.DataFrame(index=[0])\n",
    "    feature['favorite_count'] = Count_of_favorite_tweets\n",
    "    feature['friends_to_followers'] = Friends_to_follower_ratio\n",
    "    feature['statuses_count'] = Total_status_count\n",
    "    feature['def_p_img_na'] = Def_p_img_na\n",
    "    feature['def_p_img_false'] = Def_p_img_false\n",
    "    feature['def_p_img_true'] = Def_p_img_true\n",
    "    feature['def_p_na'] = Def_p_na\n",
    "    feature['def_p_false'] = Def_p_false\n",
    "    feature['def_p_true'] = Def_p_true\n",
    "    feature['age'] = Account_age\n",
    "    feature['name_letter'] = User_name_char\n",
    "    feature['name_num'] = User_name_digit\n",
    "    feature['screen_letter'] = Screen_name_char\n",
    "    feature['screen_num'] = Screen_name_digit\n",
    "    feature['des_len'] = Description_length\n",
    "#     feature['avg_tweet_per_day'] = Average_tweets_per_day\n",
    "#     feature['des_text'] = Description_tfidf\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def survival_time(created_at):\n",
    "    # get the account ages: crawl at time - created at time \n",
    "    current_time = time.localtime(time.time())\n",
    "    current_year = current_time.tm_year\n",
    "    current_month = current_time.tm_mon\n",
    "    current_day = current_time.tm_mday\n",
    "\n",
    "    meta = created_at.split(\" \")\n",
    "    created_month = meta[1]\n",
    "    if created_month == 'Jan':\n",
    "        created_month = int(1)\n",
    "    elif created_month == 'Feb':\n",
    "        created_month = int(2)\n",
    "    elif created_month == 'Mar':\n",
    "        created_month = int(3)\n",
    "    elif created_month == 'Apr':\n",
    "        created_month = int(4)\n",
    "    elif created_month == 'May':\n",
    "        created_month = int(5)\n",
    "    elif created_month == 'Jun':\n",
    "        created_month = int(6)\n",
    "    elif created_month == 'Jul':\n",
    "        created_month = int(7)\n",
    "    elif created_month == 'Aug':\n",
    "        created_month = int(8)\n",
    "    elif created_month == 'Sep':\n",
    "        created_month = int(9)\n",
    "    elif created_month == 'Oct':\n",
    "        created_month = int(10)\n",
    "    elif created_month == 'Nov':\n",
    "        created_month = int(11)\n",
    "    elif created_month == 'Dec':\n",
    "        created_month = int(12)\n",
    "    created_day = int(meta[2])\n",
    "    created_year = int(meta[5])\n",
    "\n",
    "    Account_age = (current_year - created_year) * 365 + (current_month - created_month) * 30 + (current_day - created_day)\n",
    "\n",
    "    return Account_age\n",
    "\n",
    "def counter(name):\n",
    "    # counter of char & counter of digit\n",
    "    numbers = sum(c.isdigit() for c in name)\n",
    "    words   = sum(c.isalpha() for c in name)\n",
    "\n",
    "    return numbers, words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measure the running time of the whole process of prediction through account model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "def measure_time(user_id=None, screen_name=None):\n",
    "    # measure the running time of getting the features from the input\n",
    "    start = time.clock()\n",
    "    \n",
    "    with open(\"classifier/ensemble_user_2.pkl\", \"rb\") as file_handler:\n",
    "        loaded_pickle = joblib.load(file_handler)\n",
    "    feature = get_user(screen_name=screen_name)\n",
    "    np_feature = np.asarray((feature))\n",
    "    pred_account = loaded_pickle.predict(np_feature.tolist())\n",
    "    print(pred_account[0])\n",
    "    \n",
    "    end = time.clock()\n",
    "    print('function took %0.5f ms' % ((end-start)*1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "function took 72.50400 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letheyue/anaconda2/envs/yy_py3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "measure_time(screen_name='realDonaldTrump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: test the text model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 : get the latest tweet of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeline = api.GetUserTimeline(screen_name=\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Status(ID=985858100149309441, ScreenName=realDonaldTrump, Created=Mon Apr 16 12:31:02 +0000 2018, Text='Russia and China are playing the Currency Devaluation game as the U.S. keeps raising interest rates. Not acceptable!'),\n",
       " Status(ID=985856662866202624, ScreenName=realDonaldTrump, Created=Mon Apr 16 12:25:19 +0000 2018, Text='Comey drafted the Crooked Hillary exoneration long before he talked to her (lied in Congress to Senator G), then ba… https://t.co/X4GPSNm0KK'),\n",
       " Status(ID=985529299905187840, ScreenName=realDonaldTrump, Created=Sun Apr 15 14:44:30 +0000 2018, Text='Just hit 50% in the Rasmussen Poll, much higher than President Obama at same point. With all of the phony stories a… https://t.co/J2tMvPcCtK'),\n",
       " Status(ID=985504808646971392, ScreenName=realDonaldTrump, Created=Sun Apr 15 13:07:10 +0000 2018, Text='Slippery James Comey, a man who always ends up badly and out of whack (he is not smart!), will go down as the WORST… https://t.co/YSTiN7oLWq'),\n",
       " Status(ID=985502053345751040, ScreenName=realDonaldTrump, Created=Sun Apr 15 12:56:13 +0000 2018, Text='Attorney Client privilege is now a thing of the past. I have many (too many!) lawyers and they are probably wonderi… https://t.co/pnYvIGR8Tw'),\n",
       " Status(ID=985496023555608576, ScreenName=realDonaldTrump, Created=Sun Apr 15 12:32:16 +0000 2018, Text='I never asked Comey for Personal Loyalty. I hardly even knew this guy. Just another of his many lies. His “memos” are self serving and FAKE!'),\n",
       " Status(ID=985492862958698497, ScreenName=realDonaldTrump, Created=Sun Apr 15 12:19:42 +0000 2018, Text='The Syrian raid was so perfectly carried out, with such precision, that the only way the Fake News Media could deme… https://t.co/PVFzvasea5'),\n",
       " Status(ID=985489930343321600, ScreenName=realDonaldTrump, Created=Sun Apr 15 12:08:03 +0000 2018, Text='Comey throws AG Lynch “under the bus!” Why can’t we all find out what happened on the tarmac in the back of the pla… https://t.co/54vPnoqxsl'),\n",
       " Status(ID=985487209510948864, ScreenName=realDonaldTrump, Created=Sun Apr 15 11:57:14 +0000 2018, Text='The big questions in Comey’s badly reviewed book aren’t answered like, how come he gave up Classified Information (… https://t.co/rTrDHRqD5S'),\n",
       " Status(ID=985483513704124416, ScreenName=realDonaldTrump, Created=Sun Apr 15 11:42:33 +0000 2018, Text='Unbelievably, James Comey states that Polls, where Crooked Hillary was leading, were a factor in the handling (stup… https://t.co/0WH4arK3ft'),\n",
       " Status(ID=985479145504337920, ScreenName=realDonaldTrump, Created=Sun Apr 15 11:25:12 +0000 2018, Text='RT @realDonaldTrump: So proud of our great Military which will soon be, after the spending of billions of fully approved dollars, the fines…'),\n",
       " Status(ID=985279804177027072, ScreenName=realDonaldTrump, Created=Sat Apr 14 22:13:05 +0000 2018, Text='RT @nikkihaley: https://t.co/oO3wIKolMy'),\n",
       " Status(ID=985133017256660995, ScreenName=realDonaldTrump, Created=Sat Apr 14 12:29:48 +0000 2018, Text='So proud of our great Military which will soon be, after the spending of billions of fully approved dollars, the fi… https://t.co/kZ5qqY35s1'),\n",
       " Status(ID=985130802668294144, ScreenName=realDonaldTrump, Created=Sat Apr 14 12:21:00 +0000 2018, Text='A perfectly executed strike last night. Thank you to France and the United Kingdom for their wisdom and the power o… https://t.co/oIPJVo3zQn'),\n",
       " Status(ID=984967457315139586, ScreenName=realDonaldTrump, Created=Sat Apr 14 01:31:56 +0000 2018, Text='https://t.co/6VLQYAlcto'),\n",
       " Status(ID=984877999718895616, ScreenName=realDonaldTrump, Created=Fri Apr 13 19:36:27 +0000 2018, Text='DOJ just issued the McCabe report - which is a total disaster. He LIED! LIED! LIED! McCabe was totally controlled b… https://t.co/gK2Zjw6HyE'),\n",
       " Status(ID=984828878060335109, ScreenName=realDonaldTrump, Created=Fri Apr 13 16:21:16 +0000 2018, Text='We are bringing back our factories, we are bringing back our jobs, and we are bringing back those four beautiful wo… https://t.co/nxiHk4sZZr'),\n",
       " Status(ID=984767560494313472, ScreenName=realDonaldTrump, Created=Fri Apr 13 12:17:37 +0000 2018, Text='....untruthful slime ball who was, as time has proven, a terrible Director of the FBI. His handling of the Crooked… https://t.co/GHQzyOWUT5'),\n",
       " Status(ID=984763579210633216, ScreenName=realDonaldTrump, Created=Fri Apr 13 12:01:47 +0000 2018, Text='James Comey is a proven LEAKER &amp; LIAR. Virtually everyone in Washington thought he should be fired for the terrible… https://t.co/qKF0zshrZy'),\n",
       " Status(ID=984759315046322177, ScreenName=realDonaldTrump, Created=Fri Apr 13 11:44:51 +0000 2018, Text='Tremendous pressure is building, like never before, for the Border Wall and an end to crime cradling Sanctuary Citi… https://t.co/WSvff6EI9G')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_text = list()\n",
    "index = 0\n",
    "for item in timeline:\n",
    "    index += 1\n",
    "    data = item._json\n",
    "    list_text.append(data['text'])\n",
    "    if index == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest tweet of the user is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Russia and China are playing the Currency Devaluation game as the U.S. keeps raising interest rates. Not acceptable!']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The latest tweet of the user is:\")\n",
    "list_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2 : pre-process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r\"(?P<url>https?://[^\\s]+)\"\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    try:\n",
    "        mention = re.search(pat1, text).group()\n",
    "    except:\n",
    "        mention = ''\n",
    "    try:\n",
    "        url = re.search(pat2, text).group(\"url\")\n",
    "        o = urlparse(url)\n",
    "        netloc = o.netloc\n",
    "        path = p.path\n",
    "    except:\n",
    "        netloc = ''\n",
    "        path = ''\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\u2026\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    lower_case = stripped.lower()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", lower_case)\n",
    "    letters_only = letters_only + netloc + path + mention\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = tweet_cleaner_updated(list_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text of pre-processing is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'russia and china are playing the currency devaluation game as the keeps raising interest rates not acceptable'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The text of pre-processing is:\")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 3: convert the text to vector features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('pos_hmean.p', 'rb') as fp:\n",
    "    w2v_pos_hmean_01 = pickle.load(fp, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_w2v_general(tweet, size, vectors):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tweet.split():\n",
    "        try:\n",
    "            vec += vectors[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = get_w2v_general(text, 200, w2v_pos_hmean_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector after converting we get:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.26959012, -0.30902003,  0.10471017,  0.05447358,  0.59808705,\n",
       "        -0.24565055,  0.13758163,  0.8677728 ,  0.10629074,  0.29326281,\n",
       "        -0.12304791,  0.18731175,  0.08726956, -0.13513876,  0.56175141,\n",
       "        -0.74654535, -0.83927049,  0.25109404,  0.62193509,  0.16840129,\n",
       "        -0.327807  ,  0.4963034 ,  0.60733668, -0.04265926, -0.21431528,\n",
       "        -0.29100448,  0.20359909, -0.52525007, -0.0895632 ,  0.11441323,\n",
       "        -0.08939255, -0.52311338,  0.54198102, -0.6624052 ,  0.05750201,\n",
       "        -0.34641455, -0.26974008, -0.04486086,  0.32916476,  0.30484454,\n",
       "         1.3524896 , -0.19088946, -0.04657965,  0.02105158,  0.51551128,\n",
       "         0.01641426,  0.25352309,  0.13784522, -0.54720956,  0.12815888,\n",
       "        -0.38172564,  0.73967721,  0.11105266, -0.2913123 ,  0.27487024,\n",
       "         0.80724067,  0.36642141, -0.14330417,  1.11421222,  0.56861426,\n",
       "         0.17612828, -0.33602466, -0.74988724, -0.19811932, -0.47795002,\n",
       "         0.05230433,  0.12115524, -0.00387796,  0.06582744, -0.31064717,\n",
       "         0.02391211, -0.21989024,  0.33733503, -0.23120521,  0.43415611,\n",
       "        -0.07722012, -0.45508366,  0.0320791 , -0.30656621, -0.56682764,\n",
       "        -0.47690881, -0.10729477, -0.10105071, -0.23363133,  0.21391352,\n",
       "        -0.18438183,  0.51103179, -0.31423551,  0.09344504, -0.07628579,\n",
       "         0.9443532 , -0.68772721,  0.78204907, -0.07513387, -0.04069524,\n",
       "         0.8784819 ,  0.66111114, -0.10176515,  0.03956544,  0.18175333,\n",
       "        -0.00149113,  0.377558  ,  0.03443808,  0.25576512, -0.2278002 ,\n",
       "        -0.01654955,  0.08513959, -0.24795306, -0.00383241, -0.01180734,\n",
       "         0.00292383, -0.12589616, -0.26747508, -0.10639445,  0.0259941 ,\n",
       "         0.16182695,  0.05959128,  0.02486797, -0.0875398 , -0.08874532,\n",
       "        -0.07180723, -0.09810106, -0.15340775,  0.30180805, -0.01633361,\n",
       "        -0.11250588,  0.01774054,  0.07371596, -0.08643692, -0.02075033,\n",
       "        -0.13190976,  0.13180913, -0.12279796, -0.16765232,  0.07485748,\n",
       "         0.05697557, -0.23460257, -0.04295872, -0.06778182, -0.20257146,\n",
       "        -0.16460811,  0.0057596 , -0.14577599, -0.146304  , -0.01771791,\n",
       "        -0.40075285,  0.01807525, -0.12476114,  0.29153514,  0.14363873,\n",
       "        -0.11858379,  0.13909177,  0.05865458, -0.13739856, -0.17552   ,\n",
       "        -0.05491241,  0.21050963, -0.15446141, -0.21738073,  0.06184643,\n",
       "        -0.14668234,  0.1985045 ,  0.01970345,  0.02459836,  0.14914841,\n",
       "        -0.09605275, -0.11117558,  0.0111207 ,  0.22931242,  0.10768884,\n",
       "        -0.07073115,  0.05529644, -0.14232433, -0.0669985 , -0.20444094,\n",
       "        -0.18769393,  0.03244588,  0.07036862,  0.03586568,  0.04366697,\n",
       "        -0.08794912, -0.05961664,  0.05072776,  0.0517226 , -0.09117077,\n",
       "        -0.068103  , -0.07492938, -0.13431876,  0.31030476, -0.17027295,\n",
       "        -0.07304291, -0.29263391, -0.02610421, -0.04032004,  0.00829832,\n",
       "         0.21681554, -0.08931775,  0.14240297,  0.01386646, -0.04359479]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The vector after converting we get:\")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  step 4: get the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/letheyue/anaconda2/envs/yy_py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "loaded_w2v_model = load_model('w2v_01_best_weights.10-0.9346.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = loaded_w2v_model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measure the running time of the whole process of prediction through text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_running_time(user_id=None, screen_name=None):\n",
    "    # measure the running time of getting the features from the input\n",
    "    start = time.clock()\n",
    "    # get the timeline of user\n",
    "    timeline = api.GetUserTimeline(screen_name=screen_name)\n",
    "    \n",
    "    # get the first text\n",
    "    list_text = list()\n",
    "    index = 0\n",
    "    for item in timeline:\n",
    "        index += 1\n",
    "        data = item._json\n",
    "        list_text.append(data['text'])\n",
    "        if index == 1:\n",
    "            break\n",
    "            \n",
    "    # pre-processing the data\n",
    "    text = tweet_cleaner_updated(list_text[0])\n",
    "    \n",
    "    # load the function\n",
    "    with open('pos_hmean.p', 'rb') as fp:\n",
    "        w2v_pos_hmean_01 = pickle.load(fp, encoding='latin1')\n",
    "    loaded_w2v_model = load_model('w2v_01_best_weights.10-0.9346.hdf5')\n",
    "    \n",
    "    # get the prediction value\n",
    "    text = get_w2v_general(text, 200, w2v_pos_hmean_01)\n",
    "    pred = loaded_w2v_model.predict(text)\n",
    "    print(pred[0][0])\n",
    "    \n",
    "    end = time.clock()\n",
    "    print('function took %0.5f ms' % ((end-start)*1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "function took 2559.56100 ms\n"
     ]
    }
   ],
   "source": [
    "measure_running_time(screen_name='realDonaldTrump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yy_py3",
   "language": "python",
   "name": "yy_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
